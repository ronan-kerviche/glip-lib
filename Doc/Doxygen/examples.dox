/**
\page page_Basics Basics

Glip-Lib provides image processing capabilities through graph-based network. The following graph represents a <b>pipeline</b> containing two <b>fitlers</b>. The pipeline and the filters have <b>input ports</b> and <b>output ports</b>; in this example only the pipeline ports have name. Each of the ports is linked with a <b>connection</b> to one or multiple other ports. An input port can only have one connection, while an output port may have multiple ones.

\htmlonly
<center><object data="./graphics/examplePipeline1.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

Such structures can also be nested as in the following pipeline : 

\htmlonly
<center><object data="./graphics/examplePipeline2.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

Each of the filter can process a limited number of input to a limited number of output images. These numbers depends on your hardware and drivers. A filter represents a processing units : it takes a geometry and multiple textures inputs, calls the <b>vertex program</b> for all the vertices in the geometry and finally, calls the <b>fragment program</b> for every pixel actually written in the destinations textures. Image that you can cut the input image (texture) over some random geometry, then stretch this geometry and finally paste it onto the final image while applying a computation at the same time :

\htmlonly
<center><object data="./graphics/exampleTexture1.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

This was the most general approach to how a filter work : a homographic projection of a 3D scene onto a virtual screen. However, the most used configuration is the particular case when the <b>geometry</b> is a quad covering exactly this screen (note that the <b>fragment program</b> can <i>read</i> from multiple locations but can <i>write</i> only to the assigned position and cannot change this output position) :  

\htmlonly
<center><object data="./graphics/exampleTexture2.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

It can, of course, read from multipe sources and write to multiple destinations : 

\htmlonly
<center><object data="./graphics/exampleTexture3.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

We can then summarize transformations with the following pseudo-codes : 
	\code
		# For example the transformation which takes the image as a simple matrix,
		# and which increase the dynamic range occupied by the image (contrast),
		# (scalar values given for the example) : 
		newImage = oldImage * 1.1 - 0.2; 

		# This formulation is adapted to higher level programming languages.
		# The following code is adapted to lower level  programming languages : 
		For each Pixel new_p in newImage :
			old_p = read corresponding pixel in oldImage
			new_p = old_p * 1.1 - 0.2
		endFor

		# This is the generic version, with a generic function : 
		function applyTransformationToCurrentPosition( input oldImage )
		{
			old_p = read corresponding pixel in oldImage
			return Pixel( old_p * 1.1 - 0.2 )
		}

		For each Pixel new_p in newImage :
			p = applyTransformationToCurrentPosition( oldImage )
		endFor
		# This generic function is close to what the Fragment program is : a function called for every output pixel.
	\endcode

The <i>"Hello World"</i> fragment shader, which is reproducing the input to the output is written in the GLSL language : 
	\code
		#version 130
	
		uniform sampler2D inputTexture;
		out vec4 outputTexure;
	
		void main()
		{
			// The current fragment position : 
			vec2 pos = gl_TexCoord[0].st;

			// Read the base level of the texture at the current position : 
			vec4 col = textureLod( inputTexture, pos, 0);

			// Put it in the output fragment as-is : 
			outputTexure = col;
		}
	\endcode

The code for the previous example fragment shader is simply : 
	\code
		#version 130
	
		uniform sampler2D inputTexture;
		out vec4 outputTexure;
	
		void main()
		{
			// The current fragment position : 
			vec2 pos = gl_TexCoord[0].st;

			// Read the base level of the texture at the current position : 
			vec4 col = textureLod( inputTexture, pos, 0);

			// Put it in the output fragment after transforming it : 
			outputTexure = 1.1 * col - 0.2;
		}
	\endcode

Note that in Glip-Lib, a <i>Filter</i> cannot exists outside a <i>Pipeline</i>.
**/

/**
\page page_GettingStarted Getting Started

\section sec_startGOL First example of computation with GLIP-LIB : John Conway's Game of Life

This page will present you basic use of the library. We will build a simple cellular automaton based on <a href="http://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">John Conway's Game of Life</a>. The main idea is that this engine will perform operations from a grid at a time <i>t</i> to a grid at a time <i>t+1</i>. The grid (in 2D) contains cells which can be either <i>alive</i> or <i>dead</i>. Consider a 3x3 patch within this grid, if the center cell is dead at time <i>t</i> and surrounded by exactly three neighbours alive, then it will be alive at time <i>t+1</i> or will remain dead otherwise. If the center cell is alive at time <i>t</i> and surrounded by either two or three neighbours alive, then it will stay alive at time <i>t+1</i>, or it will die otherwise.

The filter will read a local 3x3 window over the current location :
\htmlonly
<center><object data="./graphics/exampleTexture3x3.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

We will create two pipelines in order to ping-pong the outputs : 
\htmlonly
<center><object data="./graphics/exampleGameOfLifePipeline.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

We will skip the code for building the window context since it depends on the library you will be using (GLUT, GLFW, Qt, etc.). However, you can find a full example with GLFW on the main project page.

First, we build the shader code for computing the grid evolution. The file <i>game.glsl</i> contains the code for a simple fragment shader (per pixel operation). You can browse documentation on GLSL (<b>OpenGL Shading Language</b>) at this page : http://www.opengl.org/sdk/docs/manglsl/.
	\code
	/*
		Game of Life - John Conway - Rule B3S23
	*/

	#version 130

	uniform sampler2D 	inputTexture;	// input sampler
	out     vec4 		outputTexture;	// output fragment

	void main()
	{
		// Reqd and count the nature of the surrounding cells : 
		int alive = 0;
		for(int i=-1; i<=1; i++)
		{
			for(int j=-1; j<=1; j++)
			{
				vec4 c = texelFetch(inputTexture, ivec2(gl_FragCoord.xy) + ivec2(j, i), 0);
				alive += int(c.r>=1.0);
			}
		}

		// Older cell are shifted in the next channel :
		vec4 c = texelFetch(inputTexture, ivec2(gl_FragCoord.xy), 0);
		outputTexture.gba = vec3(c.rg, 1.0);

		// New state :
		if(c.r>=1.0) // The center cell was previously alive
		{
			if((alive==2) || (alive==3)) 
				outputTexture.r = 1.0; // It stays alive
			else
				outputTexture.r = 0.0; // It dies
		}
		else
		{
			if(alive==3)
				outputTexture.r = 1.0; // Birth
			else
				outputTexture.r = 0.0; // Stays dead
		}
	}
	\endcode

	Then in your C++ code : the first thing you must start with is the initialization Glew library and other OpenGL related tools :
	\code
	try // always protect your code with try / catch blocks, GLIP-Lib functions will emit Glip::Exception objects.
	{
		HandleOpenGL::init();
		// Or create an object :
		// HandleOpenGL glipObject;
	\endcode

	Then you can start to build a pipeline layout and some pipeline instances. In this case the pipeline is rather simple, it will be made of a single filter with one input (the grid at time <i>t</i>) and one output (the grid at time <i>t+1</i>) :
	\code
	// Still in the try... catch block : 
		// Create a format for the filters, this will be the size of the grid :
		HdlTextureFormat fmt(640, 480, GL_RGB, GL_UNSIGNED_BYTE, GL_NEAREST, GL_NEAREST);

		// Load a shader source code from a file :
		ShaderSource src("./game.glsl");

		// Create a filter layout using the format and the shader source :
		FilterLayout fl("GameOfLifeFilterLayout", fmt, src);
		// The filter layout will automatically create the corresponding input and output ports by analyzing the uniform samplers (input) and out vectors (output) of the shader source.

		// Create a pipeline :
		PipelineLayout pl("GameOfLifePipelineLayout");

		// Add one input and one output :
		pl.addInput("inputTexture");
		pl.addOutput("outputTexture");

		// Add an instance of the filter fl :
		pl.add(fl, "GameOfLifeFilter");
		// Here you can add mutliple filters in one pipeline.

		// For this example, we use the same name for ports of the pipeline. We can use an automatic method to make the connections :
		pl.autoConnect();

		// This is equivalent to connecting the elements with :
		//pl.connectToInput("inputTexture", "GameOfLifeFilter", "inputTexture");
		//pl.connectToOutput("GameOfLifeFilter", "outputTexture", "outputTexture");
		// The connection between two filters is : pl.connect("NameFilter1","NameOutput","NameFilter2","NameInput"); for a connection going from NameFilter1::NameOutput to NameFilter2::NameInput.

		// Create one pipeline (which will also create one cell) then add a second cell (ping-pong) : 
		Pipeline* p = new Pipeline(pl, "GameOfLifePipeline");
		int	cellAId = p->getCurrentCellID(),
			cellBId = p->createBuffersCell();
	\endcode

	Finally you can use this pipeline to process maps of states : 
	\code
		// We create a first texture and a buffer :
		HdlTexture* temp = new HdlTexture(p1->out(0).format());
		unsigned char* buffer = new unsigned char[temp.getSize()];

		// Fill with some random patterns :
		for(int j=0; j<temp->getSize(); j++)
		{
			if(rand()>0.8*RAND_MAX)
				buffer[j] = 255;
			else
				buffer[j] = 0;
		}

		// We write this initialization to the texture :
		temp->write(buffer);

		// We prepare the pipeline with this first image :
		// Pipeline << Argument 1 << Argument 2 << ... << Pipeline::Process;
		(*p) << (*temp) << Pipeline::Process;

		// Cleaning :
		delete[] buffer;
		delete temp;

		// Create a Quad inside a VBO for display :
		GeometryInstance quad(GeometryPrimitives::StandardQuad(), GL_STATIC_DRAW_ARB);

		// Now we will apply and display the computation pipeline :
		unsigned int i=0;

		while(running)
		{
			// Process and display :
			if(i%2==0)
			{
				// We write in the second cell : 
				p->changeTargetBuffersCell(cellBId);
				// Using the content of the first cell : 
				(*p) << p->out(0, cellAId) << Pipeline::Process;
				p->out(0, cellBId).bind();

			}
			else
			{
				// We write in the first cell : 
				p->changeTargetBuffersCell(cellAId);
				// Using the content of the second cell : 
				(*p) << p->out(0, cellBId) << Pipeline::Process;
				p->out(0, cellAId).bind();
			}

			// Draw it on a quad :
			quad.draw();

			// Swap buffer to screen :
			glSwapBuffers(); //or equivalent method

			i++;
		}

		// Clean :
		delete p;

		HandleOpenGL::deinit();
	}
	catch(Exception& e)
	{
		// Show exception :
		std::cerr << "An exception was caught : " << std::endl;
		std::cerr << e.what() << std::endl;
	}
	\endcode

	This will produce something close to the following animation on screen :
	<img src="./images/animation.gif" />

\section sec_pipelineScripts Pipeline Scripts

We can improve the previous pipeline construction by building a script which will contain the full description with the advantage of not requiring compilation of the C++ program when modified (the compilation of the GLSL code is made by the display driver). The Glip::Modules::LayoutLoader module enables you to use dynamic pipeline saved in a file or a standard string. It will create either a Glip::CorePipeline::PipelineLayout or a Glip::CorePipeline::Pipeline that you can use directly or combined with other pipeline structures. Here is an example of script for histogram computation and display. Check Glip::Modules::LayoutLoader documentation page for further information. We can write a file <i>gameOfLiFe.ppl</i> with the following script :
	\code
	// Description of the grid format, with the name gridFormat :
	TEXTURE_FORMAT:gridFormat(640,480,GL_RGB,GL_UNSIGNED_BYTE,GL_NEAREST,GL_NEAREST)

	// Load the shader from file game.glsl
	SOURCE:gameOfLifeShader(game.glsl)

	// Create a filter layout, the output will be a texture of format gridFormat and the fragment shader used will be gameOfLifeShader
	FILTER_LAYOUT:gameOfLifeFilter(gridFormat, gameOfLifeShader)

	// The pipeline layout to be loaded from this file (the main pipeline) will be :
	PIPELINE_MAIN:gameOfLifePipeline
	{
		// Declare the input and output port :
		INPUT_PORTS(inputTexture)
		OUTPUT_PORTS(outputTexture)

		// Declare one filter instance :
		FILTER_INSTANCE:gameOfLifeInstance(gameOfLifeFilter)

		// As the input and output ports have the same name as the ports of the filter (defined by the variables inside the shader source code) there is no need to make any connection declaration.
		// This is equivalent to :
		//CONNECTION(THIS, inputTexture, gameOfLifeInstance, inputTexture)
		//CONNECTION(gameOfLifeInstance, outputTexture, THIS, outputTexture)
	}
	\endcode

	Now we replace the pipeline declaration in the C++ code by :
	\code
	// Create a loader :
	LayoutLoader loader;

	// Load the pipeline layout from file :
	Pipeline* p = loader.getPipeline("gameOfLiFe.ppl");
	\endcode

\section sec_pipelineScriptsArguments Pipeline Scripts Arguments
	In the previous example, the script is forcing the size of the grid but you might want to decide of this size within the C++ program. In that case, you need to do a few modification both in the scripts and in the C++ code. First in the file <i>gameOfLiFe.ppl</i>, we replace the lines :
	\code
	// Description of the grid format, with the name gridFormat :
	TEXTURE_FORMAT:gridFormat(640,480,GL_RGB,GL_UNSIGNED_BYTE,GL_NEAREST,GL_NEAREST)
	\endcode

	By :
	\code
	// Receive the grid format from the loader :
	REQUIRED_FORMAT:gridFormat(inputGridFormat)
	\endcode

	And in the C++ code, we must provide this format to the loader object :
	\code
	// The grid format :
	HdlTextureFormat ourGridFormat(512,512,GL_RGB,GL_UNSIGNED_BYTE,GL_NEAREST,GL_NEAREST);

	// Create a loader :
	LayoutLoader loader;

	// Add the required format BEFORE loading the file. The name must correspond to the one expected in the file :
	loader.addRequiredElement("inputGridFormat", ourGridFormat);

	// Load the pipeline layout from file :
	PipelineLayout* pl = loader.getPipeline("gameOfLiFe.ppl");
	\endcode

	All the previously described code remain identical.

\section sec_shaderInteractivity Shader Interactivity :
	You will see that after a few thousands iterations the grid has stabilized and the is little motion of patterns in it. To remove this effect, you might want to reset the flow by starting from a new random grid. In this part, we will remove the random generation in RAM to have a random starting point computed on GPU. We will generate a texture through a Glip::Modules::ProceduralInput module.

	First we need a pipeline which will be generating a random state for each cell. In the file <i>randomSource.ppl</i> we write :
	\code
	REQUIRED_FORMAT:gridFormat(inputGridFormat)

	SOURCE:RandomSourceShader
	{
		#version 130
		// The output texture (note that there is no input) :
		out vec4 randomTexture;

		// The seed which will be modify upon each call from the C++ code :
		// (unifom means that you can set the value from outside the shader)
		uniform int seed;

		// The random generator :
		float rand(vec2 co)
		{
			return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);
		}
		void main()
		{
			float a = rand(gl_TexCoord[0].st * seed); // the current pixel position times the seed.
			randomTexture = vec4(float(a<0.8),0.0,0.0,1.0);
		}
	}

	FILTER_LAYOUT:RandomSourceFilter(gridFormat, RandomSourceShader)
	PIPELINE_MAIN:gameOfLifePipeline
	{
		OUTPUT_PORTS(randomTexture)
		// Declare one filter instance :
		FILTER_INSTANCE:randomFilter
	}
	\endcode

	In the C++ code, we build an object :
	\code
	Pipeline* randomSource = loader.getPipeline("randomSource.ppl");
	\endcode

	Then we set a reset every 100 frames in the loop and modify the seed :
	\code
	// We don't do random initialization anymore...

	// Get a direct access to the filter : 
	Filter& randomSourceFilter = (*p)[p->getElementID("RandomSourceFilter")]; 
	unsigned int i=0;

	while(running)
	{
		// Reset :
		if(i%100==0)
		{
			// We modify the variable "seed", in the shader with the current count :
			randomSourceFilter.prgm().modifyVar("seed", GL_INT, i/100*13);

			// Generate the new random grid :
			(*randomSource) << Pipeline::Process;	

			// Apply as input on pipeline 2 (because in this loop, we will use pipeline 1) :
			(*p) << randomSource->out(0) << Pipeline::Process;
		}

		// Process and display :
		if(i%2==0)
		{
			// We write in the second cell : 
			p->changeTargetBuffersCell(cellBId);
			// Using the content of the first cell : 
			(*p) << p->out(0, cellAId) << Pipeline::Process;
			p->out(0, cellBId).bind();

		}
		else
		{
			// We write in the first cell : 
			p->changeTargetBuffersCell(cellAId);
			// Using the content of the second cell : 
			(*p) << p->out(0, cellBId) << Pipeline::Process;
			p->out(0, cellAId).bind();
		}

		// Draw it on a quad :
		quad.draw();

		// Swap buffer to screen :
		glSwapBuffers(); //or equivalent method

		// Unbind :
		HdlTexture::unbind();

		i++;
	}
	\endcode

	Now the output will be reset properly every 100 frames.
**/

/**
	\page page_ColorExample Example : Per pixel operations, color modification in HSV space and mixing images

The simplest operations to think about are per-pixel operations on images. They are also the fastest as they benefit from raw parallelism. In this example, we show how to change image color in HSV space and mix two images in a single pipeline. The pipeline layout can be represented as : 
\htmlonly
<center><object data="./graphics/exampleColorChange.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

The code of the pipeline is : 
	\code
	// The input format : 
	REQUIRED_FORMAT:fmt(FormatIn_0)

	// The shader for color change : 
	SOURCE:changeColorShader
	{
		#version 130
	
		uniform sampler2D 	inputTexture;
		out vec4 		outputTexture;
	
		// These variables can be modified while executing the pipeline :
		uniform float 	saturationScal = 1.0f,	// Change in saturation.
				intensityScal = 1.0f;	// Change in intensity.

		// Conversion from RGB to HSV color space : 
		void RGBToHSV( in vec3 rgb, out vec3 hsv )
		{
		        float mn, mx, delta;

		        mn = min( min(rgb.r, rgb.g), rgb.b );
		        mx = max( max(rgb.r, rgb.g), rgb.b );
		        hsv.z = mx;

		        delta = mx - mn;

		        if( mx != 0.0 )
		        {
		                hsv.y = delta / mx;

		                if( rgb.r == mx )
		                        hsv.x = ( rgb.g - rgb.b ) / delta;
		                else if( rgb.g == mx )
		                        hsv.x = 2 + ( rgb.b - rgb.r ) / delta;
		                else
		                        hsv.x = 4 + ( rgb.r - rgb.g ) / delta;

		                hsv.x = hsv.x * 60.0;
		                if( hsv.x < 0 )
		                        hsv.x = hsv.x + 360.0;
		        }
		        else
		        {
		                hsv.y = 0;
		                hsv.x = -1;
		        }
		}

		// Conversion from HSV to RGB color space : 
		void HSVToRGB( in vec3 hsv, out vec3 rgb )
		{
		        int i;
		        float f, p, q, t;

		        if( hsv.y == 0 ) 
		                rgb = hsv.zzz;
		        else
		        {
		                hsv.x = hsv.x / 60;
		                i = int( floor( hsv.x ) );
		                f = hsv.x - i;
		                p = hsv.z * ( 1 - hsv.y );
		                q = hsv.z * ( 1 - hsv.y * f );
		                t = hsv.z * ( 1 - hsv.y * ( 1 - f ) );

		                if( i==0 )
		                        rgb = vec3(hsv.z, t, p);
		                else if( i==1 )
		                        rgb = vec3(q, hsv.z, p);
		                else if( i==2 )
		                        rgb = vec3(p, hsv.z, t);
		                else if( i==3 )
		                        rgb = vec3(p, q, hsv.z);
		                else if( i==4 )
		                        rgb = vec3(t, p, hsv.z);
		                else
		                        rgb = vec3(hsv.z, p, q);
		        }
		}
	
		void main()
		{
			// The current fragment position : 
			vec2 pos = gl_TexCoord[0].st;

			// Read the base level of the texture at the current position : 
			vec4 col = textureLod( inputTexture, pos, 0);
	
			vec3 hsv;

			// Transfer to HSV : 
			RGBToHSV( col.rgb, hsv );

			// Correction :
			hsv.y *= saturationScal;
			hsv.z *= intensityScal;
		
			// Transfer back to RGB : 
			HSVToRGB( hsv, col.rgb );

			// Write output :
			outputTexture = col;
		}
	}

	// Mix shader : 
	SOURCE:mixTwoImagesShader
	{
		#version 130

		uniform sampler2D	texture1, texture2;
		out     vec4 		mixTexture;

		void main()
		{
			// Read the color of the two input textures : 
			vec4	col1  = textureLod(texture1, gl_TexCoord[0].st, 0.0),
				col2 = textureLod(texture2, gl_TexCoord[0].st, 0.0);

			// Test if the current fragment is part of the upper or lower part of the image (the sepration is the secondary diagonal) :
			if( 1.0 - gl_TexCoord[0].s > gl_TexCoord[0].t ) 
				mixTexture = col1; // Write color from first input.
			else
				mixTexture = col2; // Write color from second input.
		}
	}

	FILTER_LAYOUT: changeColorFilter ( fmt, changeColorShader)
	FILTER_LAYOUT: mixTwoImagesFilter ( fmt, mixTwoImagesShader)

	PIPELINE_MAIN: changeColorPipeline
	{
		INPUT_PORTS( inputTexture )
		OUTPUT_PORTS( outputTexture, mixTexture )

		FILTER_INSTANCE: changeColorFilter ( changeColorFilter )
		FILTER_INSTANCE: mixTwoImagesFilter ( mixTwoImagesFilter )

		CONNECTION( THIS, inputTexture, changeColorFilter, inputTexture)
		CONNECTION( THIS, inputTexture, mixTwoImagesFilter, texture1)

		CONNECTION( changeColorFilter, outputTexture, mixTwoImagesFilter, texture2)

		CONNECTION( changeColorFilter, outputTexture, THIS, outputTexture )
		CONNECTION( mixTwoImagesFilter, mixTexture, THIS, mixTexture )
	}
	\endcode

Profile code for the uniform variables (see Glip::Modules::UniformsVarsLoader) : 
	\code
	PIPELINE:changeColorPipeline
	{
		FILTER:changeColorFilter
		{
			GL_FLOAT:intensityScal(4)
			GL_FLOAT:saturationScal(1.5)
		}
	}
	\endcode

Output example, on <i>mixTexture</i> (original is on top-left corner) :
\htmlonly
<center><a href="./images/colorChange.png"> <img src="./images/colorChange_small.png" /></a></center>
\endhtmlonly
**/

/**
	\page page_SobelExample Example : Sobel Filter

The Sobel filter is basically computing the local derivates of the intensity map. In this example we will show how to use the SHARED_CODE tag accross files. The following illustrations shows how the Sobel filter works : it reads a local 3x3 pixels window over the current location, multiplying (element-wise) the value by two 3x3 matrices : 

\htmlonly
<center><object data="./graphics/exampleTexture3x3.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

The matrices are : 

	\f$ M_x = \left( \begin{array}{ccc} -1 & 0 & 1 \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{array} \right) \quad \quad \mbox{and} \quad \quad M_y = \left( \begin{array}{ccc} -1 & -2 & -1 \\ 0 & 0 & 0 \\ 1 & 2 & 1 \end{array} \right) \f$

First we write a script file <i>convolutionTools.ppl</i> containing :
	\code
	// This code will be used to replace the tag INSERT_SHARED_CODE in all SOURCE bodies loaded.
	SHARED_CODE:convolutionShared
	{
		// Read a 3x3 matrix from the sample s, centered at position pos, use selection to mix the channels :
		void aggregate(in sampler2D s, in vec2 pos, in vec4 selection, out mat3 localRegion)
		{
			localRegion = mat3(	0.0, 0.0, 0.0,
						0.0, 0.0, 0.0,
						0.0, 0.0, 0.0);

			ivec2 sz = textureSize(s, 0);
			float sx = 1.0/(float(sz.s));
			float sy = 1.0/(float(sz.t));

			for(int i=-1; i<=1; i++)
			{
				for(int j=-1; j<=1; j++)
				{
					vec4 col = textureLod(s, pos + vec2(j*sx, i*sy), 0.0);
					localRegion[i+1][j+1] = dot(col,selection);
				}
			}
		}

		// Apply the convolution between localRegion and kernel
		void applyKernel(in mat3 localRegion, in mat3 kernel, out float value)
		{
			value = 0.0;

			for(int i=0; i<3; i++)
			{
				for(int j=0; j<3; j++)
					value += localRegion[i][j] * kernel[i][j];
			}
		}
	}
	\endcode

Then we write a second script <i>sobel.ppl</i> :
	\code
	// Include previous file :
	INCLUDE_FILE(convolutionTools.ppl)

	// Format :
	REQUIRED_FORMAT:sobelOutputFormat()

	SHARED_CODE:sobelShared
	{
		// This section will be appended at the end of the SHARED_CODE section from the included file convolutionTools.ppl.

		// The kernels for the Sobel filter :
		const mat3 kernelX = mat3(	-1.0, 0.0, 1.0,
						-2.0, 0.0, 2.0,
						-1.0, 0.0, 1.0);

		const mat3 kernelY = mat3(	-1.0, -2.0, -1.0,
						 0.0,  0.0,  0.0,
						 1.0,  2.0,  1.0);

		// Compute Sobel Filter
		void computeSobel(in mat3 localRegion, out vec4 data)
		{
			// data.x : Gx
			// data.y : Gy
			// data.p : L1 Magnitude = |Gx| + |Gy|
			// data.q : Angle = atan(Gx/Gy)

			applyKernel(localRegion, kernelX, data.x);
			applyKernel(localRegion, kernelY, data.y);

			data.p = abs(data.x) + abs(data.y);
			data.q = atan(data.y/data.x);
		}
	}

	// The Sobel Shader :
	SOURCE:sobelShader()
	{
		#version 130

		uniform sampler2D 	inputTexture;
		out     vec4 		sobelTexture;

		// Insert the content of the SHARED_CODE sections here :
		INSERT_SHARED_CODE:convolutionShared
		INSERT_SHARED_CODE:sobelShared

		void main()
		{
			mat3 localRegion;

			aggregate(inputTexture, gl_TexCoord[0].st, vec4(1.0,1.0,1.0,0.0)/3.0, localRegion);

			computeSobel(localRegion, sobelTexture);
		}
	}

	// Filter :
	FILTER_LAYOUT:sobelFilter(sobelOutputFormat, sobelShader)

	PIPELINE_MAIN:sobelPipeline()
	{
		INPUT_PORTS(inputTexture)
		OUTPUT_PORTS(sobelTexture)

		FILTER_INSTANCE:sobelFilterInstance(sobelFilter)
	}
	\endcode

	We simply load and use with the usual code :
	\code
	HdlTextureFormat imageFormat(w, h, GL_RGB, GL_UNSIGNED_BYTE);

	// Note that we will use a floating point texture on 4 components for the output :
	HdlTextureFormat sobelFormat(w, h, GL_RGBA32F, GL_FLOAT);

	HdlTexture theTexture(imageFormat);

	// Create and load the pipeline :
	Loader loader;

	load.addRequiredElement(sobelFormat,"sobelOutputFormat");

	Pipeline* sobelPipeline = loader.getPipeline("sobel.ppl", "SobelPipeline");

	// ...

	// Write in the texture :
	theTexture.write(/*...*/);

	// Process :
	(*sobelPipeline) << theTexture << Pipeline::Process

	// Use/display sobelPipeline->out(0) or sobelPipeline->out("sobelTexture")
	// ...

	// Clean :
	delete sobelPipeline;
	\endcode

Output example, only L1 magnitude :
	<img src="./images/sobelIntensity.png" />
**/

/**
	\page page_MinMaxMean Example : Reduction operation (min, max, sum, ...)

Finding the minimum or maximum instensity in an image, or computing the sum of a function over an image : \f$s = \sum_i \sum_j f(M_{i,j})\f$ is an interesting task which is naturally written on a sequential processor in pseudocode as :
	\code
	s = 0;

	for each Pixel in the image
		s = s + f(current Pixel value)
	endFor
	\endcode

This operation cannot ported directly to a parallel architecture since the access to variable s should be made from all the threads/shaders and that would be a huge bottleneck for the algorithm. We can note that the <b>order of operation does not matter</b> and <b>for every pixel processed, the result does not depend on previous value of s</b>. The key to port this algorithm to GPU is to use a simple <i>divide and conquer</i> type of algorithm.

For example, we consider the <i>max</i> operator over a texture of dimensions 512x512 (an image of 512x512 pixels and only one channel). We will use a first intermediate texture of 64x64 pixels and a second of 8x8 pixels. The first step is that the shaders are called on the first intermediate texture. Each of the 64x64 = 4096 shaders created will apply the <i>max</i> operator in a small window of 8x8 pixels of the original image. They will store their result in the intermediate 64x64 texture. Then we start back the same process but using the 64x64 texture as input and 8x8 pixels as output. At last, we can use a texture made of a single pixel and repeat the process with the intermediate 8x8 texture. Each step of the process perform a parallel (fast) reduction over a 8x8 window and give, as final result, a single pixel texture.

\htmlonly
<center><object data="./graphics/exampleReduction.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

First, we write a generic shader source file <i>genericReduction.ppl</i> for reduction opertions :
	\code
	SHARED_CODE:reductionShared
	{
		// This segment requires the use to prepare a function of the following prototype signature :
		// void reductionFunction(inout vec4 stackResult, in vec4 current, in bool firstCall)

		void reduceData(in sampler2D inputSampler, in vec2 pos, in int blocSize, out vec4 stackResult)
		{
			ivec2 sz = textureSize(inputSampler, 0);
			float sx = 1.0/(float(sz.s));
			float sy = 1.0/(float(sz.t));

			vec4 col;

			for(int i=0; i<blocSize; i++)
			{
				for(int j=0; j<blocSize; j++)
				{
					col = textureLod(inputSampler, pos + vec2(j*sx, i*sy), 0.0);
					reductionFunction(stackResult, col, i==0 && j==0);
				}
			}
		}
	}
	\endcode

Now we write the specific reduction function for min, max and sum of the red channel in the file <i>minMaxReduction.ppl</i>, and the pipeline :
	\code
	// Declare the function needed :
	SHARED_CODE:reductionFunctionShared
	{
		void reductionFunction(inout vec4 stackResult, in vec4 current, in bool firstCall)
		{
			if(firstCall)
			{
				stackResult = vec4(stackResult.r, stackResult.r, stackResult.r, 0.0);
			}
			else
			{
				stackResult.r = min(stackResult.r, current.r);
				stackResult.g = max(stackResult.g, current.r);
				stackResult.b = stackResult.b + current.r;
			}
		}
	}

	// Include file, the SHARED_CODE section in the file will be appended after the previous section :
	INCLUDE_FILE(genericReduction.ppl)

	// Intermediate format 1 :
	TEXTURE_FORMAT:intermediateTexture1(64,64,GL_RGBA32F,GL_FLOAT,GL_NEAREST,GL_NEAREST)

	// Intermediate format 2 :
	TEXTURE_FORMAT:intermediateTexture2(8,8,GL_RGBA32F,GL_FLOAT,GL_NEAREST,GL_NEAREST)

	// Result format :
	TEXTURE_FORMAT:resultFormat(1,1,GL_RGBA32F,GL_FLOAT,GL_NEAREST,GL_NEAREST)

	// The filter :
	SOURCE:reductionMMSShader
	{
		#version 130

		// Insert the compiled SHARED_CODE
		INSERT_SHARED_CODE:reductionFunctionShared
		INSERT_SHARED_CODE:reductionShared

		uniform sampler2D 	inputTexture;
		out vec4		resultTexture;

		const int blocSize = 8;

		void main()
		{
			reduceData(inputTexture, gl_TexCoord[0].st, blocSize, resultTexture);
		}
	}

	// Declare the 3 filters :
	FILTER_LAYOUT:reductionMMSFilter1(intermediateTexture1, reductionMMSShader)
	FILTER_LAYOUT:reductionMMSFilter2(intermediateTexture2, reductionMMSShader)
	FILTER_LAYOUT:reductionMMSFilter3(resultFormat, reductionMMSShader)

	// Declare the pipeline :
	PIPELINE_MAIN:reductionMMSPipeline
	{
		INPUT_PORTS(inputTexture)
		OUTPUT_PORTS(resultTexture)

                FILTER_INSTANCE:inst1(reductionMMSFilter1)
                FILTER_INSTANCE:inst2(reductionMMSFilter2)
                FILTER_INSTANCE:inst3(reductionMMSFilter3)

                // Make the connections :
                CONNECTION(THIS, inputTexture, inst1, inputTexture)
		CONNECTION(inst1, resultTexture, inst2, inputTexture)
		CONNECTION(inst2, resultTexture, inst3, inputTexture)
		CONNECTION(inst3, resultTexture, THIS, resultTexture)
	}
	\endcode

We use the ususal code to load and use this pipeline :
	\code
	// Load the pipeline :
	Loader loader;

	Pipeline* reductionPipeline = loader.getPipeline("minMaxReduction.ppl", "MMSReductionPipeline");

	// ...

	// Process :
	(*reductionPipeline) << someTexture << Pipeline::Process

	// Use/display reductionPipeline->out(0) or reductionPipeline->out("resultTexture")
	// ...

	// Clean :
	delete reductionPipeline;
	\endcode
**/

/**

	\page page_HistogramExample Example : Histogram Processing

On this page, we will describe how to build a specific class of algorithm to be suitable with GPU architecture. We will use the example of the histogram computation to illustrate the possibilities offered by Vertex Texture Fetching.

The histogram algorithm can be simply written in pseudocode as :
	\code
	set table redBins to 0
	set table greenBins to 0
	set table blueBins to 0

	for each pixel in the image
		increment redBins[current red color]
		increment greenBins[current green color]
		increment blueBins[current green color]
	end
	\endcode

As discussed in the \ref page_GettingStarted page, this is not directly transferable to shader code since fragment shaders are only emitted per written fragments. Thus there is no way to chose the destination texel according to input. But, what we can do is generate a geometry which can be controlled by a vertex shader. Remember that a Glip::CorePipeline::Filter is always using a vertex shader and a fragment shader. When the vertex shader is not detailed, the filter uses a generic one. In the case of a RGB image we will use a 3D grid as the geometry with 3 layers and, in each, as much points as pixels in the input image (can be lowered in order to improve performances). Each point is associated to one of the color (red, green or blue) of one pixel image. In the vertex shader, we can read the color value of the texture corresponding texel and modify the location of the point dynamically.

\htmlonly
<center><object data="./graphics/exampleTextureVTF.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

We can write a Pipeline Script <i>histogram.ppl</i> as :
	\code
	// Get the format of the input image :
	REQUIRED_FORMAT:inputFormat(inputTextureFormat)
	// 256 bins in RGB :
	TEXTURE_FORMAT:histogramBinsFormat(256, 1, GL_RGBA32F, GL_FLOAT, GL_NEAREST, GL_LINEAR)

	CALL:FORMAT_SCALE_SIZE(inputFormat, 0.25, 0.25, reducedFormat) // Avoid computing on the full image (optional)
	CALL:FORMAT_TO_CONSTANT(reducedFormat, reducedFormat)
	CALL:GENERATE_SAME_SIZE_3D_GRID(reducedFormat, grid) // Generate the grid of points.

	SOURCE:HistogramVertexShader
	{
		#version 130
		precision highp float;

		uniform sampler2D inputTexture;

		INSERT(reducedFormat)

		void main()
		{
			// Vertex texture fetching :
			vec4 col = texelFetch(inputTexture, ivec2(gl_Vertex.xy), 0);
			float sel = 0.0;
			// Compute the "Payload"
			if(gl_Vertex.z==0.0) // Red plane
			{
				gl_FrontColor = vec4(1.0,0.0,0.0,1.0);
				sel = col.r;
			}
			else if(gl_Vertex.z==1.0) // Green plane
			{
				gl_FrontColor = vec4(0.0,1.0,0.0,1.0);
				sel = col.g;
			}
			if(gl_Vertex.z==2.0) // Blue plane
			{
				gl_FrontColor = vec4(0.0,0.0,1.0,1.0);
				sel = col.b;
			}
			else // Discard
			{
				gl_FrontColor = vec4(0.0,0.0,0.0,1.0);
				sel = -1.0;
			}

			gl_Position = vec4((sel-0.5)*2.0, 0.0, 0.0, 1.0); // set new point position to the color intensity in [-1.0,1.0] interval.
		}
	}

	// The fragment shader :
	SOURCE:HistogramFragmentShader
	{
		#version 130
		precision highp float;

		out vec4 histogramBins;

		INSERT(reducedFormat)

		void main()
		{
			// Prepare normalization constant :
			float nrm = 1.0/float(reducedFormat.s*reducedFormat.t);
			histogramBins = gl_Color*nrm;
			// Write :
			histogramBins.a = 1.0;
		}
	}

	FILTER_LAYOUT:HistogramFilter(histogramBinsFormat, HistogramFragmentShader, HistogramVertexShader, grid)
	{
		// Set the blending so that we sum the counts :
		GL_BLEND(GL_ONE, GL_ONE, GL_FUNC_ADD)
	}

	PIPELINE_MAIN:HistogramPipeline
	{
		INPUT_PORTS(inputTexture)
		OUTPUT_PORTS(histogramBins)
		FILTER_INSTANCE:HistogramFilter(HistogramFilter)
	}
	\endcode

	Now we have to load this pipeline with the usual code :
	\code
	HdlTextureFormat imageFormat(w, h, GL_RGB, GL_UNSIGNED_BYTE);
	HdlTexture theTexture(imageFormat);

	Loader loader;

	// Load the standard modules :
	LayoutLoaderModules::addBasicModules(loader);

	// Give the size of the current texture : 
	loader.addRequiredElement("inputTextureFormat", imageFormat);

	// Create and load the pipeline :
	Pipeline* histogramPipeline = loader.getPipeline("histogram.ppl", "HistogramPipeline");

	// Write in the texture :
	theTexture.write(/*...*/);

	// Process :
	(*histogramPipeline) << theTexture << Pipeline::Process

	// Use/display histogramPipeline->out(0) or histogramPipeline->out("histogramBins")
	// ...

	// Clean :
	delete histogramPipeline;
	\endcode

	This will write into the 1D texture the density (normalized sum) of rescpectively, the red, the green and the blue components. We can elaborate something a little bit more sophisticated in order to super-impose the histogram on top of the image from which it was generated.

	We write a file <i>prettyHistogram.ppl</i>
	\code
	// Include the file containing the Histogram pipeline :
	INCLUDE(histogram.ppl)

	// Get the format of the input image :
	REQUIRED_FORMAT:outputFormat(inputTextureFormat)

	// Shader plotting the histograms on top of the image :
	SOURCE:PlotHistogramShader
	{
		#version 130
		precision highp float;

		uniform sampler2D histogramBins, inputTexture;
		out vec4 outputTexture;

		uniform float scale = 1.0;
		uniform int noBackground = 0;

		void main()
		{
			vec2 pos = gl_TexCoord[0].st;
			vec4 hist = textureLod(histogramBins, vec2(pos.s, 0.0), 0);
			vec4 col = textureLod(inputTexture, pos, 0);

			bool 	rTest = (pos.t>(1.0-hist.r*scale)),
				gTest = (pos.t>(1.0-hist.g*scale)),
				bTest = (pos.t>(1.0-hist.b*scale));

			if(noBackground>0 && (rTest || gTest || bTest))
				col = vec4(0.0, 0.0, 0.0, 1.0);

			outputTexture.r = rTest ? 1.0 : col.r;
			outputTexture.g = gTest ? 1.0 : col.g;
			outputTexture.b = bTest ? 1.0 : col.b;
			outputTexture.a = 1.0;
		}
	}

	FILTER_LAYOUT:PlotHistogramFilter(outputFormat, PlotHistogramShader)

	// Create the pipeline :
	PIPELINE_MAIN:PlotHistogramPipeline
	{
		INPUT_PORTS(inputTexture)
		OUTPUT_PORTS(histogramBins, outputTexture) 
		FILTER_INSTANCE:HistogramFilter(HistogramFilter)
		FILTER_INSTANCE:PlotHistogramFilter(PlotHistogramFilter)
	}
	\endcode

	The C++ program will load this with :
	\code
	HdlTextureFormat imageFormat(w, h, GL_RGB, GL_UNSIGNED_BYTE);
	HdlTexture theTexture(imageFormat);

	Loader loader;

	// Load the standard modules :
	LayoutLoaderModules::addBasicModules(loader);

	// Give the size of the current texture : 
	loader.addRequiredElement("inputTextureFormat", imageFormat);

	Pipeline* prettyHistogramPipeline = loader.getPipeline("prettyHistogram.ppl", "PrettyHistogramPipeline");

	// Write in the texture :
	theTexture.write(/*...*/);

	// Process :
	(*prettyHistogramPipeline) << theTexture << Pipeline::Process

	// Use/display prettyHistogramPipeline->out(0) or prettyHistogramPipeline->out("histogramBins") for the actual histogram
	// or prettyHistogramPipeline->out(1) or prettyHistogramPipeline->out("outputTexture") for the enhanced image.
	// ...

	// Clean :
	delete prettyHistogramPipeline;
	\endcode

An example of output :
	<img src="./images/exampleHistogram.png" />
**/

/**
	\page page_LucasKanade Example : Simple Lucas Kanade optical flow estimator

In this example we present a simple approximation to the <a href="http://en.wikipedia.org/wiki/Lucas%E2%80%93Kanade_method">Lucas Kanade Optical Flow Estimator</a>. The goal is to solve the 2x2 system describing the change in intensity by translation. We write the Pipeline Script <i>LucasKanade.ppl</i> which will contain both the algorithm implementation and a representation stage :

\htmlonly
<center><object data="./graphics/exampleOpticalFlow.svg" type="image/svg+xml"></object></center>
\endhtmlonly 

	\code
	// The different formats needed :
	TEXTURE_FORMAT:computationFormatFloat(512, 512,GL_RGBA32F, GL_FLOAT, GL_NEAREST, GL_NEAREST, GL_CLAMP, GL_CLAMP)
	TEXTURE_FORMAT:visualizationFormat(512, 512, GL_RGB, GL_UNSIGNED_BYTE, GL_NEAREST, GL_NEAREST, GL_CLAMP, GL_CLAMP)
	TEXTURE_FORMAT:sideBySideFormat(512, 256, GL_RGB, GL_UNSIGNED_BYTE, GL_NEAREST, GL_NEAREST, GL_CLAMP, GL_CLAMP)

	SOURCE:derivativesShader
	{
		#version 130

		uniform sampler2D 	latest, oldest;
		out     vec4 		derivatives, grayScale;

		void main()
		{
			const float step = 1.0/512.0;

			// Compute all the derivates of the intensity image :
			vec4 col11 = textureLod(latest, gl_TexCoord[0].st, 0);
			vec4 col01 = textureLod(latest, gl_TexCoord[0].st + vec2(-step, 0.0), 0);
			vec4 col21 = textureLod(latest, gl_TexCoord[0].st + vec2( step, 0.0), 0);
			vec4 col10 = textureLod(latest, gl_TexCoord[0].st + vec2(0.0, -step), 0);
			vec4 col12 = textureLod(latest, gl_TexCoord[0].st + vec2(0.0,  step), 0);
			vec4 colB  = textureLod(oldest, gl_TexCoord[0].st, 0);

			float 	v11 = (col11.r+col11.g+col11.b)/3.0,
				v01 = (col01.r+col01.g+col01.b)/3.0,
				v21 = (col21.r+col21.g+col21.b)/3.0,
				v10 = (col10.r+col10.g+col10.b)/3.0,
				v12 = (col12.r+col12.g+col12.b)/3.0,
				vB  = (colB.r+colB.g+colB.b)/3.0;

			derivatives.r = (v21-v01)/2.0;
			derivatives.g = (v12-v10)/2.0;
			derivatives.b = (v11-vB)/2.0;

			grayScale.rgb = vec3(v11,v11,v11);
		}
	}

	SOURCE:opticalFlowShader
	{
		#version 130

		uniform sampler2D derivatives;
		out vec4 opticalFlow;

		void main()
		{
			const float step = 1.0/512.0;
			const int wSize = 5;
			const float mWindow = pow((2*wSize+1)*step/(3.14159265),2.0);
			float w = 0.0;
			int i, j;

			vec2 	pos,
				delta;
			vec4 	col;
			float 	x = 0.0,
				y = 0.0,
				A = 0.0,
				B = 0.0,
				C = 0.0,
				idet = 0.0;

			// Build the 2x2 matrix and the Intensity vector: :
			for( i=-wSize; i<=wSize; i++)
			{
				for( j=-wSize; j<=wSize; j++)
				{
					vec2 delta = vec2( i*step, j*step);
					w 	= cos(dot(delta,delta)*40.0);
					pos   	= gl_TexCoord[0].st + delta;
					col   	= textureLod(derivatives, pos, 0.0);
					A 	= A + w*col.r*col.r;
					B 	= B + w*col.g*col.g;
					C 	= C + w*col.r*col.g;
					x 	= x + w*col.r*col.b;
					y 	= y + w*col.g*col.b;
				}
			}

			// Solve 2x2 matrix inverse :
			idet = 1.0/(A*B-C*C);

			if(idet>1000.0)
				idet = 0.0;

			opticalFlow.r = idet*(-B*x+C*y);
			opticalFlow.g = idet*( C*x-A*y);
		}
	}

	SOURCE:visualizationShader
	{
		#version 130

		uniform sampler2D opticalFlow;
		out vec4 visualization;

		const float eLim = 0.1;
		const float ctr = 0.1;

		void getHSL(in vec2 d, out vec3 res)
		{
			float   e	= (d.x*d.x + d.y*d.y)/2.0;

			// Angles :
			float 	h	= (atan(d.x, d.y) + 3.14159)/1.047;
			int 	prt 	= int(h/2.0);
			float 	hp 	= h-float(prt)*2.0;
			float 	v 	= 1.0-abs(hp-1.0);

			if(h<1.0)
				res = vec3(1.0,v,0.0)*e;
			else if(h<2.0)
				res = vec3(v,1.0,0.0)*e;
			else if(h<3.0)
				res = vec3(0.0,1.0,v)*e;
			else if(h<4.0)
				res = vec3(0.0,v,1.0)*e;
			else if(h<5.0)
				res = vec3(v,0.0,1.0)*e;
			else //if(h<6.0)
				res = vec3(1.0,0.0,v)*e;
		}

		void main()
		{
			visualization.a = 1.0;

			// Draw a small legend for the directions :
			if(gl_TexCoord[0].s<ctr && gl_TexCoord[0].t<ctr)
			{
				getHSL(gl_TexCoord[0].st-vec2(ctr,ctr)/2.0, visualization.rgb);
				visualization.rgb = visualization.rgb*400.0;
			}
			else // The rest of the image :
			{
				vec4 flow = textureLod(opticalFlow, gl_TexCoord[0].st, 0);

				// Make the visualization easier by using HSL color space and associate directions with color.
				getHSL(flow.rg, visualization.rgb);
				visualization.rgb = visualization.rgb*0.5;
			}
		}
	}

	SOURCE:sideBySideShader
	{
		#version 130

		uniform sampler2D latest, visualization;
		out vec4 sideBySide;

		void main()
		{
			vec2 pos = gl_TexCoord[0].st;

			// Separate the output image in left image and right image :
			if(pos.s<=0.5)
			{
				// The original image goes on left :
				pos.s = pos.s*2.0;
				sideBySide  = textureLod(latest, pos, 0);
			}
			else
			{
				// The motion image goes on right :
				pos.s = (pos.s-0.5)*2.0;
				sideBySide = textureLod(visualization, pos, 0);
			}
		}
	}

	FILTER_LAYOUT:derivatives(computationFormatFloat,derivativesShader)
	FILTER_LAYOUT:opticalFlow(computationFormatFloat,opticalFlowShader)
	FILTER_LAYOUT:visualizationFilter(visualizationFormat,visualizationShader)
	FILTER_LAYOUT:sideBySideFilter(sideBySideFormat,sideBySideShader)

	PIPELINE_MAIN:opticalFlow
	{
		INPUT_PORTS(latest, oldest)
		OUTPUT_PORTS(grayScale, derivatives, opticalFlow, visualization, sideBySide)

		FILTER_INSTANCE:instDerivatives(cDerivatives)
		FILTER_INSTANCE:instOpticalFlow(cOpticalFlow)
		FILTER_INSTANCE:instVisualization(cMix)
		FILTER_INSTANCE:instSideBySide(cSBS)

		// Automatic connection will be performed.
	}
	\endcode

	\htmlonly
	Example of recording of the output port <b>sideBySide</b> with <a href="http://ffmpeg.org/">FFMPEG</a> : <BR>
	<center>
		<iframe width="560" height="315" src="http://www.youtube-nocookie.com/embed/0uhZFEhIG-0?rel=0" frameborder="0" allowfullscreen></iframe><BR>
		Animation Big Buck Bunny under Creative Commons License, see <a href="http://www.bigbuckbunny.org/">www.bigbuckbunny.org</a>.<BR>
	</center><BR>
	\endhtmlonly
**/

/**
	\page page_BilateralFilter Example : Simple small kernel bilateral filter
	
	This example shows the implementation of a simple <a href="http://en.wikipedia.org/wiki/Bilateral_filter">bilateral filter</a> (for small kernel size).
	\code
	REQUIRED_FORMAT:fmt( FormatIn_0 )

	SOURCE:bilateralShader
	{
		#version 130
	
		uniform sampler2D inputBilateral;
		out vec4 outputBilateral;
	
		uniform float 	rI = 0.270,		// The intensity radius (in pixels).
				rL = 1.71;		// The geometric radius (in pixels).
		uniform int	windowSize = 5;		// The window size (in pixels).
	
		float gaussian(float l, float r)
		{
			return exp(-l*l/(2.0f*r*r));
		}

		void main()
		{
			// Get the sizes : 
			int nWindow = windowSize / 2;
			ivec2 sz = textureSize(inputBilateral, 0);
			float sx = 1.0/(float(sz.s));
			float sy = 1.0/(float(sz.t));

			vec4 	outCol = vec4(0.0, 0.0, 0.0, 0.0),
				refCol = textureLod(inputBilateral, gl_TexCoord[0].st, 0.0);

			float nrm = 0.0;

			// Compute the kernel : 
			for(int i=-nWindow; i<=nWindow; i++)
			{
				for(int j=-nWindow; j<=nWindow; j++)
				{
					vec4 	col 	= textureLod(inputBilateral, gl_TexCoord[0].st + vec2(j*sx, i*sy), 0.0);
					float 	a 	= gaussian( distance(col, refCol), rI ),
						b	= gaussian( length(vec2(j, i)), rL );
					outCol += col * a * b;
					nrm += a * b;
				}
			}

			outputBilateral = outCol / nrm;
		}
	}

	FILTER_LAYOUT:bilateralFilter(fmt,bilateralShader)

	PIPELINE_MAIN:bilateralPipeline
	{
		INPUT_PORTS(inputBilateral)
		OUTPUT_PORTS(outputBilateral)

		FILTER_INSTANCE:bilateralFilterInstance(bilateralFilter)
	}
	\endcode

	Output example for 3 stages of 5x5 bilateral filter : 
	<img src="./images/galaxyBeforeBilateral.png" /> 
	<div align="center">Before filtering</div>
	<img src="./images/galaxyAfterBilateral.png" />
	<div align="center">After filtering</div>
**/

/**
	\page page_ProceduralImageGeneration Example : Image Procedural Generation

	\code
	TEXTURE_FORMAT:outputCircleFormat(1024, 1024, GL_RGBA, GL_UNSIGNED_BYTE, GL_LINEAR, GL_LINEAR)
	CALL:FORMAT_TO_CONSTANT(outputCircleFormat)
	
	SOURCE:circleShader
	{
		#version 130
	
		out vec4 	outputTexture;
		uniform vec4	background = vec4(0.1, 0.1, 0.1, 1),
				color = vec4(1, 0, 1, 1);
		uniform vec2 	center = vec2(0.5, 0.5);
		uniform float 	radius = 0.1;

		INSERT(outputCircleFormat)

		void main()
		{
			vec2 p = gl_FragCoord.xy / vec2(outputCircleFormat);

			// If the current pixel is closer to the center than the radius :
			//if(distance(p,center)<=radius)
			//	outputTexture = color;
			//else
			//	outputTexture = background;

			// One line version : 
			outputTexture = mix(color, background, step(radius, distance(p,center)));

			// Anti-Aliasing version : 
			//const float e = 0.005:
			//outputTexture = mix(color, background, smoothstep(radius-e/2, radius+e/2, distance(p,center)));
		}
	}

	FILTER_LAYOUT:circleFilter(outputCircleFormat, circleShader)

	PIPELINE_MAIN:circlePipeline
	{
		OUTPUT_PORTS(outputTexture)
		FILTER_INSTANCE:circleFilter
	}
	\endcode

	\code
	TEXTURE_FORMAT:outputLogoFormat(1024, 1024, GL_RGBA, GL_UNSIGNED_BYTE, GL_LINEAR, GL_LINEAR)
	CALL:FORMAT_TO_CONSTANT(outputLogoFormat)

	SOURCE:glipLogoShader
	{
		#ifndef MODIFY_GLIP_LOGO
		const float 	thickness = 0.150,
				aaThicknes = 0.001,
				xOutterLow = 0.2,
				xInnerLow = 0.3,
				xInnerHigh = 0.73,
				xOutterHigh = 0.8,
				yLineTop = 0.2,
				yLineMiddle = 0.5,
				yLineBottom = 0.8;
		#endif
	
		// Distance to a segment : 
		float dSegment(vec2 p, vec2 a, vec2 b)
		{
			float l = (a.x-b.x)*(a.x-b.x) + (a.y-b.y)*(a.y-b.y);
			float t = dot(p - a, b - a) / l;
			if (t < 0.0)
				return distance(p, a);
			else if (t > 1.0)
				return distance(p, b);
			else
				return distance(p, a + t * (b - a));
		}

		// Distance to red path (3 segments) :
		float dRed(vec2 p)
		{
			float d = min(dSegment(p, vec2(xOutterLow, yLineMiddle), vec2(xInnerLow, yLineMiddle)),
				  min(dSegment(p, vec2(xInnerLow, yLineMiddle), vec2(xInnerHigh, yLineTop)),
				      dSegment(p, vec2(xInnerHigh, yLineTop), vec2(xOutterHigh, yLineTop)) ));
			return smoothstep(aaThicknes, -aaThicknes, d-thickness);
		}
	
		// Distance to green path (3 segments) :
		float dGreen(vec2 p)
		{
			float d = min(dSegment(p, vec2(xOutterLow, yLineTop), vec2(xInnerLow, yLineTop)),
				  min(dSegment(p, vec2(xInnerLow, yLineTop), vec2(xInnerHigh, yLineBottom)),
				      dSegment(p, vec2(xInnerHigh, yLineBottom), vec2(xOutterHigh, yLineBottom)) ));
			return smoothstep(aaThicknes, -aaThicknes, d-thickness);
		}

		// Distance to blue path (3 segments) :
		float dBlue(vec2 p)
		{
			float d = min(dSegment(p, vec2(xOutterLow, yLineBottom), vec2(xInnerLow, yLineBottom)),
				  min(dSegment(p, vec2(xInnerLow, yLineBottom), vec2(xInnerHigh, yLineMiddle)),
				      dSegment(p, vec2(xInnerHigh, yLineMiddle), vec2(xOutterHigh, yLineMiddle)) ));
			return smoothstep(aaThicknes, -aaThicknes, d-thickness);
		}

		// Get the logo, combining all the paths : 
		vec4 getLogo(vec2 p)
		{
			vec4 l = vec4(dRed(p), dGreen(p), dBlue(p), 0.0);
			l = vec4(l.r*(1.0-l.g)*(1.0-l.b), l.g*(1.0-l.b), l.b, max(l.r, max(l.g, l.b)));
			return l;
		}
	}

	SOURCE:glipShader
	{
		#version 130
		out vec4 logo;

		INSERT(outputLogoFormat)
	
		// Uncomment the next line to modify the parameters of the drawing : 
		//#define MODIFY_GLIP_LOGO

		#ifdef MODIFY_GLIP_LOGO
		uniform float 	thickness = 0.150,
				aaThicknes = 0.002,
				xOutterLow = 0.2,
				xInnerLow = 0.3,
				xInnerHigh = 0.73,
				xOutterHigh = 0.8,
				yLineTop = 0.2,
				yLineMiddle = 0.5,
				yLineBottom = 0.8;
		#endif

		INSERT(glipLogoShader)

		void main(void)
		{
			// Draw at normalized position p : 
			vec2 p = gl_FragCoord.xy/outputLogoFormat;
			logo = getLogo(p);
		}
	}

	FILTER_LAYOUT:glipFilter(outputLogoFormat, glipShader)

	PIPELINE_MAIN:glipPipeline
	{
		OUTPUT_PORTS(logo)
		FILTER_INSTANCE:glipFilter
	}
	\endcode
**/

/**
	\page page_UseGlipStudio Tool : GlipStudio

\section sec_glipStudioIntro GlipStudio
	GlipStudio is a small IDE for GLIP-Lib : load images and prototype quickly pipelines, filters and profiles in the editor and the uniform variables manager. Once the pipelines are saved to the disk, you can use them in applications based on GLIP-Lib.

\section sec_getGlipStudio Get GlipStudio 
	In order to use GlipStudio, you can get it from the following sources : 

	- <b>Binaries for Windows (64 bits) : http://sourceforge.net/projects/glip-lib/files/GlipStudio_x64_win.zip/download</b>
	
	- Get from source (Linux/Windows, (32/64 bits)) : clone git repository at http://sourceforge.net/p/glip-lib/code/ci/master/tree/ (for Windows user, you can use this tool : http://git-scm.com/downloads).
	
	Building the code, what is needed : 
	
	- Linux : GCC 4.6+, CMake, Qt SDK.

	- Windows : Visual Studio (Express) 2012, Qt SDK (with OpenGL support <i>"Qt 5.1.0 for Windows (VS 2012, OpenGL)"</i>, can be downloaded at http://qt-project.org/downloads).

	<b>Build steps on Linux :</b> 

	- In directory <i>GLIP-Lib/</i>, run script file <i>compile.sh</i> or CMake generation :
		\code cmake . -G"Unix Makefiles" -DCMAKE_BUILD_TYPE=Release \endcode

	- In directory <i>Examples/GlipStudio/</i>, run usual build procedure for Qt application : 
		\code qmake && make -j \endcode
	
	<b>Build steps on Windows :</b>

	- Open project file in <i>Project_VS/GLIP-Lib/</i> with Visual Studio. Include 'GLIP-Lib/include/' in search path and choose the target compilation (32/64 bits, release). Build the project.

	- With Qt Creator, open project file in <i>Examples/GlipStudio/</i> (<i>Examples/GlipStudio/GlipStudio.pro</i>). Set the target to release and build the project.

\section sec_UsingGlipStudio Using Glip Studio

How to use <b>GlipStudio</b> : 
	- <b>Load images</b> : in the lower pane, in the <b>Resources</b> tab, click the <b>Image</b> menu, then <b>Load image...</b>. Choose the images to load in the dialog box. Once loaded they appear in the <b>Images</b> section with their names, resolutions, GL modes, and filtering. Click on a line to display the corresponding image in the <b>Display Window</b>.
	- <b>Load a pipeline</b> : in the right pane, in the <b>File</b> menu, choose <b>Open</b>. The application is distributed with several examples in the directory <i>Filters</i> (PPL files). For instance, load pipeline <i>changeHSL_HSV.ppl</i>, its source code will appear in a new tab. Do no modify the code for the moment, and click <b>Refresh | Compile</b> in the menu bar. The pipeline is created and its inputs and outputs are now listed in the Resource manager (<b>Resources</b> tab in the lower pane). In this manager, select one image from the <b>Images</b> section and connect it as the input of the pipeline : click the <b>Connect</b> menu and choose the unique input available. Note that the input size as changed and this particular pipeline must be refreshed every time this happens : click <b>Refresh | Compile</b> in the menu bar of the editor (or press <b><i>F5</i></b> or <b><i>Ctrl+r</i></b> on your keyboard). Select the first output or second output image, they should display almost identical images than the input.
	- <b>Modify uniform variables</b> : without recompiling the program, you are allowed to modify variables dynamically. Go in the <b>Uniforms</b> tab, and modify the values in the boxes (<b><i>hint</i></b> : you can let your mouse over a box a use your mouse wheel or trackpad virtual wheel in order to modify the values more smoothly).
	- <b>Save uniform variables</b> : if you were to recompile the pipeline after a modification of the code, you would loose the current settings in the <i>uniform</i> variables. In order to avoid this problem, go in the <b>Uniforms</b> tab, and, from here, you can save to a file. This is time costly for numerous modification, so you can use the <b>Main Library</b> menu from which you will be able to quickly save and load one profile per Pipeline.
	- <b>Save the output</b> : you can save the output of a pipeline either in memory as a duplicate or to the disk. Go in the <b>Resources</b> tab, select the output, click the <b>Image</b> menu and choose <b>Copy as new resource...</b> for a in-memory copy (you will be ask for a name for the new resource) or choose <b>Save output as...</b> to save the image to the disk (in JPEG, PNG, BMP, PPM, etc.).

Visualization commands, select the visualization window (containing the image) by clicking it first : 
<CENTER>
Command       					| Designation
----------------------------------------------- | --------------------------
Escape 						| Escape fullscreen mode
Directional arrows  				| Translation
Return  					| Toggle fullscreen on/off 
Space 						| Reset transformation
+/- 						| Zoom in / out
f/d 						| Rotate left / right
Left click and drag 				| Translation
Right click and drag 				| Rotation
Holding Control key + left click and drag 	| Rotation
Double left click 				| Toggle fullscreen on/off 
Double right click 				| Reset transformation
Mouse wheel 					| Zoom in / out
</CENTER>

\section sec_Captures Screenshots
	<img src="./images/glipstudio_1.png" width="1024" />
	<BR>
	<img src="./images/glipstudio_2.png" width="1024" />
	<BR>
	<img src="./images/glipstudio_3.png" width="1024" />
	<BR>
	<img src="./images/glipstudio_4.png" width="1024" />
	
**/

/**
	\page page_UseGlipCompute Tool : GlipCompute

\section sec_IntroGlipCompute Presentation
	<b>glip-compute</b> is a command line tool built for GNU/Linux. It requires the host machine to run a X server and allow you to generate graphics, process images and save results to image files without invoking a GUI.

\section sec_CommandsGlipCompute Commands
\verbatim
Use GLIP-Lib from the command line to process or generate images.
glip-compute [-p FILENAME] [-u FILENAME] [-i {1, 2, 3, ...} FILENAME]
	     [-o {1, 2, 3, ...} FILENAME] [-r FILENAME]

Mandatory arguments :
-p, --pipeline	Pipeline filename. See the online documentation for more
		information about pipeline scripts.
		E.g. : -p pipeline.ppl

Optional, passing the inputs/outputs as aguments (single processing
command) :
 -i, --input	Input to the pipeline, can be indexed by a number or by the
		name of the input port (they do not need to be in the
		correct order), followed by a filename. All the input
		ports must receive an input image.
		E.g. : -i 0 inputImage.ext
		       -i inputPortName inputImage.ext
 -o, --output	Output to the pipeline, can be indexed by a number or by the
		name of the input port (they do not need to be in the
		correct order), followed by a filename. Only the ouput
		ports listed will be saved, others will be discarded
		E.g. : -o 0 outputImage.ext
		       -o outputPortName outputImage.ext
 -u, --uniforms	Load a set of uniform variables script. See the online 
		documentation about these.
		E.g. : -u uniformsFile.uvd

Optional, passing the processing commands as a file (can be used to
generate multiple processing commands using the same pipeline) :
 -r, --process	Load a set of processing commands from a file. See
		the section "Processing Commands" for more information
		E.g. : -r commandsFile.txt

Optional, passing the processing commands from stdin.

Other options : 
 -f, --format	Set how the input format requirements are passed to the
		pipeline. You can use C notation with either %d
		indicating the use of the numerical indexing, or %s
		indicating the use of the port name instead.
		E.g. : -f inputFormat%d
		       -f someName_%s
 -m, --memory	Set the amount of memory (given in MB) available to 
		be reusable on the device. This helps reduce significantly
		the overhead induced by loading the image files (textures
		are conserved as long as possible on device, depending on
		their usage frequency).
		Default is 128 MB.
 -s, --preserve	Preserve the pipeline definition after its first creation.
		New inputs sizes will be ignored as required elements.
 -d, --display	Name of the host, X server and display to target for the
		context.
		E.g. : -d host:xServer.screenId
		       -d localhost:0.0
 -h, --help	Show this help and stops.
 -t, --template	Show a list of templates script (Pipeline, Uniforms and 
		Command) and stops.
 -v, --version	Show the version and stops.
 -V, --Version  Start a context, show the informations and stop.
		You can set the display variable before using this option.

PROCESSING COMMANDS
  Processing commands describe which resource to use in order to repeat
the operation with little overhead. These commands are given in a format
close to the format of the Pipeline or Uniforms script. They should be :

PROCESS
{
	INPUT( inFilename0.ext, inFilename1.ext, ...)
	OUTPUT( outFilename0.ext, outFilename1.ext, ...)
}

  This description must match the number of input of the pipeline, and be
given in the correct order. As for the outputs, it is possible to discard
one by using the keyword VOID instead of a filename. Filtering can be
specified per input with the following set of commands :

GL_TEXTURE_MIN_FILTER( filterForInput0, filterForInput1, ...)
GL_TEXTURE_MAG_FILTER( filterForInput0, filterForInput1, ...)
GL_TEXTURE_WRAP_S( filterForInput0, filterForInput1, ...)
GL_TEXTURE_WRAP_T( filterForInput0, filterForInput1, ...)

It is also possible to supply specific Uniforms variables on a per command
basis via two methods. The first, from a file, by adding the following
line in the body of the command :

UNIFORMS( filename.uvd )

  The second adding the code directly via the body :

UNIFORMS
{
	// Uniforms description goes here.
}

EXAMPLE
  For a pipeline with one input and at least one ouput :
     glip-compute -p myPipeline.ppl -i 0 inputImage.png -o 0 outputImage.
\endverbatim

\section sec_XRemoteOpenGL X And Remote OpenGL
	This section describes how to access remote computation capability of a server. It requires the server to be running a X Server with at least one display open. You will not be able to see any graphics via this method alone (graphics will be generated on the display (might be virtual) associated to the distant machine). But this might be sufficient and useful for <i>glip-compute</i>. It also requires you to have a session opened on the distant machine.

	Steps :
	- On the remote machine, save the following values (once, when you have physical access) :
	\code
	echo -e "LOCAL DISPLAY    : $DISPLAY\nLOCAL XAUTHORITY : $XAUTHORITY"	
	\endcode
	- Log to the machine via SSH and enable X forwarding :
	\code
	ssh -X username@remote
	\endcode
	- Have a look at the values of DISPLAY (should be something like :10.0) and XAUTHORITY (might be empty) :
	\code
	echo -e "REMOTE DISPLAY    : $DISPLAY\nREMOTE XAUTHORITY : $XAUTHORITY"
	\endcode
	- Change the values of $DISPLAY and $XAUTHORITY :
	\code
	export DISPLAY=<LOCAL DISPLAY VALUE>
	export XAUTHORITY=<LOCAL XAUTHORITY VALUE>
	\endcode
	- Test with either <i>glxinfo</i>, <i>glewinfo</i> or <i>glip-compute</i>.

\section On AWS/EC2
	On a GPU instance, install the required packages :
	\code
	# yum update
	# yum install cmake git glut glut-devel glx* xorg-x11*
	\endcode

	Install <b>freeimage</b> from source (use the -j option for multi-thread compilation) :
	\code
	$ make
	# make install
	$ make -f Makefile.fip
	# make -f Makefile.fip install
	\endcode

	Compile and install GlipLib, GlipCompute :
	\code 
	$ cmake . -DCMAKE_BUILD_TYPE=release && make
	# make install
	\endcode

	Start the X server with a display at the address <i>:0</i> :
	\code
	# X :0
	\endcode

	Connect with X forwarding, change the targeted display and test :
	\code
	$ ssh -X [...]
	$ export DISPLAY=:0
	$ glxinfo
	$ glip-compute -V
	\endcode
**/

